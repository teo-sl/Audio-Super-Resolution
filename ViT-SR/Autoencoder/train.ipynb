{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./drive/MyDrive/vit_sr/pickled.zip -d .\n",
    "\n",
    "!rm ./UnzippedDataset/train/137.mus\n",
    "!rm ./UnzippedDataset/train/899.mus\n",
    "!rm ./UnzippedDataset/train/1194.mus\n",
    "!rm ./UnzippedDataset/train/462.mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTConfig, ViTModel, AdamW\n",
    "\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "\n",
    "import librosa\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, device='cpu'):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=(3,3), padding=1), \n",
    "                        nn.GELU(), \n",
    "                        nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=(3,3), padding=1)\n",
    "        ).to(device) \n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        convolved_input = self.block(inputs)\n",
    "        return convolved_input + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, device='cpu'):\n",
    "        super(GenerativeNetwork, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = 64\n",
    "        self.patch_size = 16\n",
    "        configuration = ViTConfig(num_attention_heads=8, num_hidden_layers=8, hidden_size=self.hidden_size, patch_size=self.patch_size, num_channels=1, image_size=1024)\n",
    "        self.vit = ViTModel(configuration).to(self.device)\n",
    "        self.model = nn.Sequential(\n",
    "                        # bring the image back to the original size\n",
    "                        nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=4, padding=1, stride=2), \n",
    "                        nn.GELU(), \n",
    "                      \n",
    "                        # skip connections\n",
    "                        ResidualBlock(),\n",
    "                        nn.GELU(),                      \n",
    "                        ResidualBlock(),\n",
    "                        nn.GELU(),\n",
    "                        ResidualBlock(),\n",
    "                        nn.GELU(), \n",
    "                        ResidualBlock(),\n",
    "                        nn.GELU(),  \n",
    "        ).to(device)\n",
    "        \n",
    "\n",
    "    def patch_to_img(self, x, patch_size):\n",
    "        B, NumPatches, HiddenSize = x.shape\n",
    "        x = x.reshape(B, NumPatches, 1, HiddenSize)\n",
    "        x = x.reshape(B, NumPatches, 1, patch_size, patch_size)\n",
    "        x = x.permute(0, 1, 3, 4, 2)\n",
    "        x = x.reshape(B, int(math.sqrt(NumPatches)), int(math.sqrt(NumPatches)), patch_size, patch_size, 1)\n",
    "        x = x.permute(0,1,3,2,4,5)\n",
    "        new_h = x.shape[1] * x.shape[2]\n",
    "        new_w = x.shape[3] * x.shape[4]\n",
    "        x = x.reshape(B, new_h, new_w, 1)\n",
    "        x = x.swapaxes(3, 1)\n",
    "        x = x.swapaxes(3, 2)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if inputs.device == 'cpu':\n",
    "            inputs = inputs.to(self.device)\n",
    "        vit_res = self.vit(pixel_values=inputs)\n",
    "        inputs = vit_res.last_hidden_state[:, 1:, :]\n",
    "        patch_size_after_vit = int(math.sqrt(inputs.shape[2]))\n",
    "        inputs = self.patch_to_img(inputs, patch_size_after_vit)\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LHB_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path, ext):\n",
    "        self.path = path\n",
    "        self.ext = ext\n",
    "        self.len = len(os.listdir(self.path))\n",
    "        self.items_in_dir = os.listdir(self.path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        name = self.path + '/' + self.items_in_dir[idx] \n",
    "\n",
    "        with open(name, 'rb') as fd:\n",
    "            song = pickle.load(fd)\n",
    "\n",
    "        return song[:1318970]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './UnzippedDataset/train'\n",
    "\n",
    "train_ds = LHB_Dataset(train_path, 'mus')\n",
    "\n",
    "print(train_ds[0].shape)\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_generator = torch.Generator(device='cpu')\n",
    "train_generator.manual_seed(13)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                                            dataset=train_ds, \n",
    "                                            batch_size=1, \n",
    "                                            shuffle=True,\n",
    "                                            generator=train_generator\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GenerativeNetwork(device)\n",
    "optimizer_gen = AdamW(generator.parameters(), lr=1e-4) \n",
    "loss_gen = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def save_model(model, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    filename = path + '/generator_' + str(datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")) + '.pt'\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator,epochs,train_loader):\n",
    "    i = 0\n",
    "    for i in range(epochs):\n",
    "      i += 1\n",
    "      history = []\n",
    "      print(f\"Start epoch {i}\")\n",
    "      total_loss = 0\n",
    "      k = 0\n",
    "      for data_batch in train_loader:\n",
    "\n",
    "        batch_lb = []\n",
    "        batch_hb = []\n",
    "      \n",
    "        for data in data_batch:\n",
    "\n",
    "          data = data.squeeze(dim=0)  \n",
    "\n",
    "          train_stft = librosa.stft(np.asarray(data), n_fft=4096, win_length=4096, window=signal.windows.hamming(4096))\n",
    "          train_spectrogram = torch.tensor(librosa.amplitude_to_db(abs(train_stft)))\n",
    "          train_spectrogram = (train_spectrogram - train_spectrogram.min())/(train_spectrogram.max()-train_spectrogram.min())\n",
    "\n",
    "          lb = train_spectrogram[1:1025,:1024]\n",
    "          hb = train_spectrogram[1025:,:1024]\n",
    "\n",
    "          lb = lb.reshape(1,1024,1024)\n",
    "          hb = hb.reshape(1,1024,1024)\n",
    "\n",
    "          batch_lb.append(lb)\n",
    "          batch_hb.append(hb)\n",
    "        \n",
    "        batch_lb = torch.stack(batch_lb).to(device)\n",
    "        batch_hb = torch.stack(batch_hb).to(device)\n",
    "\n",
    "        gen_hb = generator(batch_lb).to(device)\n",
    "\n",
    "        optimizer_gen.zero_grad()\n",
    "        loss = loss_gen(gen_hb, batch_hb)\n",
    "        total_loss += loss.detach()\n",
    "        k+=1\n",
    "        loss.backward()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        print(f'Loss: {loss.item()}')\n",
    "        history.append(loss.item())\n",
    "\n",
    "      total_loss = total_loss / k\n",
    "      if i% 40 == 0:\n",
    "        save_model(generator,\"models\")\n",
    "\n",
    "      plt.plot(history,label=\"loss\")\n",
    "\n",
    "      plt.show()\n",
    "      \n",
    "      print(\"Mean loss\"+str(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator, 100, trainloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
