{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./drive/MyDrive/vit_sr/pickled16.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ./UnzippedDataset/train/113166.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import librosa\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Conv1DTranspose, BatchNormalization, LeakyReLU, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(input_size=(32, 129)):\n",
    "    inputs = tf.keras.Input(input_size)\n",
    "\n",
    "    # 32 x 129\n",
    "    x = Conv1D(256, 7, strides=2,padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x_skip_1 = x\n",
    "\n",
    "    x = Conv1D(512, 5, strides=2,padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x_skip_2 = x\n",
    "\n",
    "    x = Conv1D(512, 3, strides=2,padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x_skip_3 = x\n",
    "\n",
    "    x = Conv1D(1024, 3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    \n",
    "\n",
    "    x = Conv1DTranspose(512, 3,strides=2, padding='same')(x)\n",
    "    x = Add()([x, x_skip_3])\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    \n",
    "\n",
    "    x = Conv1DTranspose(512, 5,strides=2, padding='same')(x)\n",
    "\n",
    "    x = Add()([x, x_skip_2])\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    \n",
    "\n",
    "    x = Conv1DTranspose(256, 7,strides=2, padding='same')(x)\n",
    "    x = Add()([x, x_skip_1])\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv1DTranspose(128, 9,strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    input = tf.keras.Input((32, 128))\n",
    "\n",
    "    x = Conv1D(1024, 7, strides=2, padding='same')(input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv1D(1024, 5, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv1D(1024, 3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(2048)(x)\n",
    "    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "d_optim = tf.keras.optimizers.Adam(learning_rate=10e-7, beta_1=0.5)\n",
    "discriminator.compile(optimizer=d_optim, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "z = tf.keras.Input((32, 129))\n",
    "fake = generator(z)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(fake)\n",
    "\n",
    "combined = tf.keras.Model(z, [fake, valid])\n",
    "\n",
    "c_optim = tf.keras.optimizers.Adam(learning_rate=10e-4, beta_1=0.5)\n",
    "# define the loss for the combined model as the adversarial loss and the content loss (MSE) with weighting\n",
    "combined.compile(optimizer=c_optim, loss=['mse', 'binary_crossentropy'], loss_weights=[0.1, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio(path):\n",
    "    song,sr = librosa.load(path,sr=16000)\n",
    "    stft = librosa.stft(np.asarray(song), n_fft=512, window='hamming', hop_length=256)\n",
    "    spectrogram = librosa.amplitude_to_db(np.abs(stft))\n",
    "    spectrogram = (spectrogram - np.min(spectrogram)) / (np.max(spectrogram) - np.min(spectrogram))\n",
    "    \n",
    "    DIM = 32\n",
    "    PTS = spectrogram.shape[1]//DIM\n",
    "    lb = []\n",
    "    hb = []\n",
    "    for i in range(PTS):\n",
    "        lb.append([spectrogram[:129,i*DIM:(i+1)*DIM]])\n",
    "        hb.append([spectrogram[129:,i*DIM:(i+1)*DIM]])\n",
    "    lb = np.array(lb)\n",
    "    hb = np.array(hb)\n",
    "\n",
    "    lb = lb.reshape(-1,32,129)\n",
    "    hb = hb.reshape(-1,32,128)\n",
    "\n",
    "    lb = lb[:32,:,:]\n",
    "    hb = hb[:32,:,:]\n",
    "    return lb,hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator,discriminator,gan,epochs,batch_size,train_path):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    ones=np.ones(batch_size*32)\n",
    "    zeros=np.zeros(batch_size*32)\n",
    "    files = glob.glob(train_path+\"/*.mp3\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      np.random.shuffle(files)\n",
    "      batch_lb = []\n",
    "      batch_hb = []\n",
    "      for file in np.random.choice(files,batch_size):\n",
    "        lb,hb = convert_audio(file)\n",
    "        batch_lb.append(lb)\n",
    "        batch_hb.append(hb)\n",
    "      batch_lb = np.array(batch_lb)\n",
    "      batch_hb = np.array(batch_hb)\n",
    "      \n",
    "      try:\n",
    "        batch_lb = batch_lb.reshape(-1,32,129)\n",
    "        batch_hb = batch_hb.reshape(-1,32,128)\n",
    "      except:\n",
    "        continue\n",
    "      \n",
    "      fake_hb=generator.predict(batch_lb)\n",
    "\n",
    "      d_loss_real, d_acc_real = discriminator.train_on_batch(batch_hb,ones)\n",
    "      d_loss_fake,d_acc_fake = discriminator.train_on_batch(fake_hb,zeros)\n",
    "\n",
    "      d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "\n",
    "      g_loss = gan.train_on_batch(batch_lb, [batch_hb, ones])\n",
    "\n",
    "      d_losses.append(d_loss)\n",
    "      g_losses.append(g_loss)\n",
    "\n",
    "      if epoch % 1 == 0:\n",
    "          print(f\"epoch: {epoch+1}/{epochs}, d_loss: {d_loss}, g_loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "while True:\n",
    "  train(generator, discriminator, combined, 100, 16, \"./UnzippedDataset/train\")\n",
    "  combined.loss.loss_weights=[0.1, 0.001+j*0.002]\n",
    "  generator.save(f'gen_norm_{j}.h5')\n",
    "  j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
